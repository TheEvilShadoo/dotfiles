//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32139144
// Unknown Toolkit Version
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_75, texmode_independent
.address_size 64

	// .globl	DynamicKernel_nop_fsum_fsum_fsum

.entry DynamicKernel_nop_fsum_fsum_fsum(
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsum_param_0,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsum_param_1,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsum_param_2
)
{
	.reg .pred 	%p<119>;
	.reg .b32 	%r<28>;
	.reg .f64 	%fd<85>;
	.reg .b64 	%rd<30>;


	ld.param.u64 	%rd7, [DynamicKernel_nop_fsum_fsum_fsum_param_0];
	ld.param.u64 	%rd29, [DynamicKernel_nop_fsum_fsum_fsum_param_1];
	ld.param.u64 	%rd9, [DynamicKernel_nop_fsum_fsum_fsum_param_2];
	mov.b32 	%r10, %envreg3;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %tid.x;
	add.s32 	%r14, %r13, %r10;
	mad.lo.s32 	%r1, %r12, %r11, %r14;
	setp.gt.s32 	%p1, %r1, 3;
	mov.f64 	%fd82, 0d0000000000000000;
	mov.f64 	%fd79, %fd82;
	@%p1 bra 	$L__BB0_32;

	and.b32  	%r15, %r1, 1;
	setp.eq.b32 	%p2, %r15, 1;
	mov.pred 	%p3, 0;
	xor.pred  	%p4, %p2, %p3;
	not.pred 	%p5, %p4;
	mov.f64 	%fd79, 0d0000000000000000;
	mov.u32 	%r25, %r1;
	@%p5 bra 	$L__BB0_3;

	mul.wide.s32 	%rd10, %r1, 8;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.f64 	%fd42, [%rd11];
	abs.f64 	%fd43, %fd42;
	setp.gtu.f64 	%p6, %fd43, 0d7FF0000000000000;
	add.f64 	%fd44, %fd42, 0d0000000000000000;
	selp.f64 	%fd79, 0d0000000000000000, %fd44, %p6;
	add.s32 	%r25, %r1, 1;

$L__BB0_3:
	setp.gt.s32 	%p7, %r1, 2;
	@%p7 bra 	$L__BB0_32;

	add.s32 	%r26, %r25, -2;
	mul.wide.s32 	%rd12, %r25, 8;
	add.s64 	%rd13, %rd9, %rd12;
	add.s64 	%rd28, %rd13, 8;

$L__BB0_5:
	add.s64 	%rd3, %rd28, -8;
	ld.global.f64 	%fd5, [%rd28+-8];
	abs.f64 	%fd6, %fd5;
	setp.gtu.f64 	%p8, %fd6, 0d7FF0000000000000;
	@%p8 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_6;

$L__BB0_17:
	add.f64 	%fd78, %fd79, 0d0000000000000000;
	bra.uni 	$L__BB0_18;

$L__BB0_6:
	setp.lt.f64 	%p9, %fd5, 0d0000000000000000;
	setp.gt.f64 	%p10, %fd79, 0d0000000000000000;
	and.pred  	%p11, %p10, %p9;
	@%p11 bra 	$L__BB0_8;

	setp.geu.f64 	%p12, %fd79, 0d0000000000000000;
	setp.leu.f64 	%p13, %fd5, 0d0000000000000000;
	or.pred  	%p14, %p12, %p13;
	@%p14 bra 	$L__BB0_16;

$L__BB0_8:
	neg.f64 	%fd7, %fd79;
	setp.eq.f64 	%p15, %fd5, %fd7;
	mov.f64 	%fd78, 0d0000000000000000;
	@%p15 bra 	$L__BB0_18;

	setp.eq.f64 	%p16, %fd5, 0d0000000000000000;
	setp.eq.f64 	%p17, %fd79, 0d8000000000000000;
	or.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB0_16;

	add.f64 	%fd46, %fd79, %fd5;
	abs.f64 	%fd8, %fd46;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd8;
	}
	and.b32  	%r17, %r16, 2146435072;
	setp.eq.s32 	%p19, %r17, 2146435072;
	mul.f64 	%fd47, %fd6, 0d3D30000000000000;
	setp.gt.f64 	%p20, %fd8, %fd47;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB0_16;

	abs.f64 	%fd9, %fd7;
	mul.f64 	%fd48, %fd9, 0d3D30000000000000;
	setp.gt.f64 	%p22, %fd8, %fd48;
	@%p22 bra 	$L__BB0_16;

	setp.gtu.f64 	%p23, %fd8, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd14, %fd8;
	setp.gt.s64 	%p24, %rd14, 9007199254740991;
	or.pred  	%p25, %p23, %p24;
	@%p25 bra 	$L__BB0_15;

	setp.gtu.f64 	%p26, %fd6, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd15, %fd6;
	setp.gt.s64 	%p27, %rd15, 9007199254740991;
	or.pred  	%p28, %p26, %p27;
	@%p28 bra 	$L__BB0_15;

	setp.le.f64 	%p29, %fd9, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd16, %fd9;
	setp.lt.s64 	%p30, %rd16, 9007199254740992;
	and.pred  	%p31, %p29, %p30;
	@%p31 bra 	$L__BB0_16;

$L__BB0_15:
	mul.f64 	%fd50, %fd6, 0d3CF0000000000000;
	setp.lt.f64 	%p32, %fd8, %fd50;
	mul.f64 	%fd51, %fd9, 0d3CF0000000000000;
	setp.lt.f64 	%p33, %fd8, %fd51;
	and.pred  	%p34, %p32, %p33;
	@%p34 bra 	$L__BB0_18;

$L__BB0_16:
	add.f64 	%fd78, %fd79, %fd5;

$L__BB0_18:
	ld.global.f64 	%fd13, [%rd3+8];
	abs.f64 	%fd14, %fd13;
	setp.gtu.f64 	%p35, %fd14, 0d7FF0000000000000;
	@%p35 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_19;

$L__BB0_30:
	add.f64 	%fd79, %fd78, 0d0000000000000000;
	bra.uni 	$L__BB0_31;

$L__BB0_19:
	setp.lt.f64 	%p36, %fd13, 0d0000000000000000;
	setp.gt.f64 	%p37, %fd78, 0d0000000000000000;
	and.pred  	%p38, %p37, %p36;
	@%p38 bra 	$L__BB0_21;

	setp.geu.f64 	%p39, %fd78, 0d0000000000000000;
	setp.leu.f64 	%p40, %fd13, 0d0000000000000000;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB0_29;

$L__BB0_21:
	neg.f64 	%fd15, %fd78;
	setp.eq.f64 	%p42, %fd13, %fd15;
	mov.f64 	%fd79, 0d0000000000000000;
	@%p42 bra 	$L__BB0_31;

	setp.eq.f64 	%p43, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p44, %fd78, 0d8000000000000000;
	or.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB0_29;

	add.f64 	%fd53, %fd78, %fd13;
	abs.f64 	%fd16, %fd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r18}, %fd16;
	}
	and.b32  	%r19, %r18, 2146435072;
	setp.eq.s32 	%p46, %r19, 2146435072;
	mul.f64 	%fd54, %fd14, 0d3D30000000000000;
	setp.gt.f64 	%p47, %fd16, %fd54;
	or.pred  	%p48, %p46, %p47;
	@%p48 bra 	$L__BB0_29;

	abs.f64 	%fd17, %fd15;
	mul.f64 	%fd55, %fd17, 0d3D30000000000000;
	setp.gt.f64 	%p49, %fd16, %fd55;
	@%p49 bra 	$L__BB0_29;

	setp.gtu.f64 	%p50, %fd16, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd17, %fd16;
	setp.gt.s64 	%p51, %rd17, 9007199254740991;
	or.pred  	%p52, %p50, %p51;
	@%p52 bra 	$L__BB0_28;

	setp.gtu.f64 	%p53, %fd14, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd18, %fd14;
	setp.gt.s64 	%p54, %rd18, 9007199254740991;
	or.pred  	%p55, %p53, %p54;
	@%p55 bra 	$L__BB0_28;

	setp.le.f64 	%p56, %fd17, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd19, %fd17;
	setp.lt.s64 	%p57, %rd19, 9007199254740992;
	and.pred  	%p58, %p56, %p57;
	@%p58 bra 	$L__BB0_29;

$L__BB0_28:
	mul.f64 	%fd57, %fd14, 0d3CF0000000000000;
	setp.lt.f64 	%p59, %fd16, %fd57;
	mul.f64 	%fd58, %fd17, 0d3CF0000000000000;
	setp.lt.f64 	%p60, %fd16, %fd58;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB0_31;

$L__BB0_29:
	add.f64 	%fd79, %fd78, %fd13;

$L__BB0_31:
	add.s64 	%rd28, %rd28, 16;
	add.s32 	%r26, %r26, 2;
	setp.lt.s32 	%p62, %r26, 2;
	@%p62 bra 	$L__BB0_5;

$L__BB0_32:
	add.f64 	%fd22, %fd79, 0d0000000000000000;
	setp.lt.s32 	%p63, %r1, -4;
	@%p63 bra 	$L__BB0_48;

	add.s32 	%r7, %r1, 4;
	mov.f64 	%fd82, 0d0000000000000000;
	mov.u32 	%r27, 0;

$L__BB0_34:
	mov.f64 	%fd23, %fd82;
	mov.u32 	%r8, %r27;
	ld.global.f64 	%fd24, [%rd29];
	abs.f64 	%fd25, %fd24;
	setp.gtu.f64 	%p64, %fd25, 0d7FF0000000000000;
	@%p64 bra 	$L__BB0_46;
	bra.uni 	$L__BB0_35;

$L__BB0_46:
	add.f64 	%fd82, %fd23, 0d0000000000000000;
	bra.uni 	$L__BB0_47;

$L__BB0_35:
	setp.lt.f64 	%p65, %fd24, 0d0000000000000000;
	setp.gt.f64 	%p66, %fd23, 0d0000000000000000;
	and.pred  	%p67, %p66, %p65;
	@%p67 bra 	$L__BB0_37;

	setp.geu.f64 	%p68, %fd23, 0d0000000000000000;
	setp.leu.f64 	%p69, %fd24, 0d0000000000000000;
	or.pred  	%p70, %p68, %p69;
	@%p70 bra 	$L__BB0_45;

$L__BB0_37:
	neg.f64 	%fd26, %fd23;
	setp.eq.f64 	%p71, %fd24, %fd26;
	mov.f64 	%fd82, 0d0000000000000000;
	@%p71 bra 	$L__BB0_47;

	setp.eq.f64 	%p72, %fd24, 0d0000000000000000;
	setp.eq.f64 	%p73, %fd23, 0d8000000000000000;
	or.pred  	%p74, %p73, %p72;
	@%p74 bra 	$L__BB0_45;

	add.f64 	%fd62, %fd23, %fd24;
	abs.f64 	%fd27, %fd62;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd27;
	}
	and.b32  	%r22, %r21, 2146435072;
	setp.eq.s32 	%p75, %r22, 2146435072;
	mul.f64 	%fd63, %fd25, 0d3D30000000000000;
	setp.gt.f64 	%p76, %fd27, %fd63;
	or.pred  	%p77, %p75, %p76;
	@%p77 bra 	$L__BB0_45;

	abs.f64 	%fd28, %fd26;
	mul.f64 	%fd64, %fd28, 0d3D30000000000000;
	setp.gt.f64 	%p78, %fd27, %fd64;
	@%p78 bra 	$L__BB0_45;

	setp.gtu.f64 	%p79, %fd27, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd20, %fd27;
	setp.gt.s64 	%p80, %rd20, 9007199254740991;
	or.pred  	%p81, %p79, %p80;
	@%p81 bra 	$L__BB0_44;

	setp.gtu.f64 	%p82, %fd25, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd21, %fd25;
	setp.gt.s64 	%p83, %rd21, 9007199254740991;
	or.pred  	%p84, %p82, %p83;
	@%p84 bra 	$L__BB0_44;

	setp.le.f64 	%p85, %fd28, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd22, %fd28;
	setp.lt.s64 	%p86, %rd22, 9007199254740992;
	and.pred  	%p87, %p85, %p86;
	@%p87 bra 	$L__BB0_45;

$L__BB0_44:
	mul.f64 	%fd66, %fd25, 0d3CF0000000000000;
	setp.lt.f64 	%p88, %fd27, %fd66;
	mul.f64 	%fd67, %fd28, 0d3CF0000000000000;
	setp.lt.f64 	%p89, %fd27, %fd67;
	and.pred  	%p90, %p88, %p89;
	@%p90 bra 	$L__BB0_47;

$L__BB0_45:
	add.f64 	%fd82, %fd23, %fd24;

$L__BB0_47:
	add.s32 	%r27, %r8, 1;
	setp.lt.u32 	%p91, %r27, 6;
	setp.lt.s32 	%p92, %r8, %r7;
	and.pred  	%p93, %p91, %p92;
	add.s64 	%rd29, %rd29, 8;
	@%p93 bra 	$L__BB0_34;

$L__BB0_48:
	setp.gt.f64 	%p94, %fd22, 0d0000000000000000;
	setp.lt.f64 	%p95, %fd82, 0d0000000000000000;
	and.pred  	%p96, %p94, %p95;
	@%p96 bra 	$L__BB0_50;

	setp.geu.f64 	%p97, %fd22, 0d0000000000000000;
	setp.leu.f64 	%p98, %fd82, 0d0000000000000000;
	or.pred  	%p99, %p97, %p98;
	@%p99 bra 	$L__BB0_59;

$L__BB0_50:
	neg.f64 	%fd33, %fd22;
	setp.eq.f64 	%p100, %fd82, %fd33;
	mov.f64 	%fd84, 0d0000000000000000;
	@%p100 bra 	$L__BB0_60;

	setp.eq.f64 	%p101, %fd82, 0d0000000000000000;
	setp.eq.f64 	%p102, %fd22, 0d8000000000000000;
	or.pred  	%p103, %p102, %p101;
	@%p103 bra 	$L__BB0_59;

	add.f64 	%fd69, %fd22, %fd82;
	abs.f64 	%fd34, %fd69;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd34;
	}
	and.b32  	%r24, %r23, 2146435072;
	setp.eq.s32 	%p104, %r24, 2146435072;
	@%p104 bra 	$L__BB0_59;

	abs.f64 	%fd35, %fd82;
	mul.f64 	%fd70, %fd35, 0d3D30000000000000;
	setp.gt.f64 	%p105, %fd34, %fd70;
	@%p105 bra 	$L__BB0_59;

	abs.f64 	%fd36, %fd33;
	mul.f64 	%fd71, %fd36, 0d3D30000000000000;
	setp.gt.f64 	%p106, %fd34, %fd71;
	@%p106 bra 	$L__BB0_59;

	setp.gtu.f64 	%p107, %fd34, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd23, %fd34;
	setp.gt.s64 	%p108, %rd23, 9007199254740991;
	or.pred  	%p109, %p107, %p108;
	@%p109 bra 	$L__BB0_58;

	setp.gtu.f64 	%p110, %fd35, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd24, %fd35;
	setp.gt.s64 	%p111, %rd24, 9007199254740991;
	or.pred  	%p112, %p110, %p111;
	@%p112 bra 	$L__BB0_58;

	setp.le.f64 	%p113, %fd36, 0d001FFFFFFFFFFFFF;
	mov.b64 	%rd25, %fd36;
	setp.lt.s64 	%p114, %rd25, 9007199254740992;
	and.pred  	%p115, %p113, %p114;
	@%p115 bra 	$L__BB0_59;

$L__BB0_58:
	mul.f64 	%fd73, %fd35, 0d3CF0000000000000;
	setp.lt.f64 	%p116, %fd34, %fd73;
	mul.f64 	%fd74, %fd36, 0d3CF0000000000000;
	setp.lt.f64 	%p117, %fd34, %fd74;
	and.pred  	%p118, %p116, %p117;
	@%p118 bra 	$L__BB0_60;

$L__BB0_59:
	add.f64 	%fd84, %fd22, %fd82;

$L__BB0_60:
	mul.wide.s32 	%rd26, %r1, 8;
	add.s64 	%rd27, %rd7, %rd26;
	st.global.f64 	[%rd27], %fd84;
	ret;

}

  